{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Processos Estoc\u00e1sticos","text":"<p>Bem-vindo ao meu reposit\u00f3rio de estudos! Este projeto foi desenvolvido para organizar de forma clara e intuitiva a teoria e a resolu\u00e7\u00e3o de exerc\u00edcios da disciplina.</p>"},{"location":"#sumario-da-disciplina","title":"\ud83d\udcda Sum\u00e1rio da Disciplina","text":"<p>Navegue pelos cap\u00edtulos abaixo para acessar os resumos te\u00f3ricos e as listas de exerc\u00edcios resolvidos:</p>"},{"location":"#1-cadeias-de-markov-em-tempo-discreto","title":"\ud83d\udd39 1. Cadeias de Markov em Tempo Discreto","text":"<ul> <li>1.1 No\u00e7\u00f5es Preliminares e Exemplos</li> <li>1.2 Espa\u00e7o de Estados Finito</li> <li>1.3 An\u00e1lise de Estados (Transientes/Recorrentes)</li> <li>1.4 Reversibilidade</li> <li>1.5 MCMC (Metropolis-Hastings &amp; Gibbs)</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 1</li> </ul>"},{"location":"#2-processos-de-poisson-e-aplicacoes","title":"\ud83d\udd39 2. Processos de Poisson e Aplica\u00e7\u00f5es","text":"<ul> <li>2.1 O Processo de Poisson: Defini\u00e7\u00e3o e Hip\u00f3teses</li> <li>2.2 Distribui\u00e7\u00e3o Exponencial e Tempos de Chegada</li> <li>2.3 Propriedades Avan\u00e7adas (Thinning/Superposi\u00e7\u00e3o)</li> <li>2.4 Varia\u00e7\u00f5es e Aplica\u00e7\u00f5es do Modelo</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 2</li> </ul>"},{"location":"#3-cadeias-de-markov-em-tempo-continuo","title":"\ud83d\udd39 3. Cadeias de Markov em Tempo Cont\u00ednuo","text":"<ul> <li>3.1 O Modelo e Matriz Geradora Q</li> <li>3.2 Comportamento Assint\u00f3tico e Kolmogorov</li> <li>3.3 Cadeia Imersa e Tempos de Espera</li> <li>3.7 Cadeias de Nascimentos e Mortes</li> <li>3.8 Aplica\u00e7\u00f5es: Filas Markovianas</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 3</li> </ul>"},{"location":"#4-processos-de-renovacao","title":"\ud83d\udd39 4. Processos de Renova\u00e7\u00e3o","text":"<ul> <li>4.1 Defini\u00e7\u00f5es Fundamentais e Constru\u00e7\u00e3o</li> <li>4.2 Teoremas de Renova\u00e7\u00e3o (Blackwell/Grandes N\u00fameros)</li> <li>4.3 Idade, Vida Residual e o Paradoxo da Inspe\u00e7\u00e3o</li> <li>4.5 Processos com Atraso e Estacionariedade</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 4</li> </ul>"},{"location":"#5-martingales","title":"\ud83d\udd39 5. Martingales","text":"<ul> <li>5.1 Filtra\u00e7\u00f5es e Defini\u00e7\u00e3o de Martingale</li> <li>5.2 Exemplos Cl\u00e1ssicos e Urna de Polya</li> <li>5.3 Tempos de Parada e Amostragem Opcional</li> <li>5.4 Teoremas de Converg\u00eancia</li> <li>5.5 Desigualdades de Doob e Azuma</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 5</li> </ul>"},{"location":"#6-movimento-browniano","title":"\ud83d\udd39 6. Movimento Browniano","text":"<ul> <li>6.1 Defini\u00e7\u00e3o Formal e Constru\u00e7\u00e3o de L\u00e9vy</li> <li>6.4 Propriedade de Markov e Princ\u00edpio da Reflex\u00e3o</li> <li>6.5 MB Geom\u00e9trico e Modelo Black-Scholes</li> <li>6.6 Varia\u00e7\u00e3o Quadr\u00e1tica e Trajet\u00f3rias</li> <li>6.7 Introdu\u00e7\u00e3o \u00e0 Integral de It\u00f4 e SDEs</li> <li>\ud83d\udcd3 Exerc\u00edcios Resolvidos - Cap 6</li> </ul> <p>\u00daltima atualiza\u00e7\u00e3o: Fevereiro de 2026</p>"},{"location":"capitulo1/exercicios/","title":"Exerc\u00edcios Resolvidos: Cadeias de Markov","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos principais t\u00f3picos abordados no Cap\u00edtulo 1.</p>"},{"location":"capitulo1/exercicios/#ex11","title":"1. Classifica\u00e7\u00e3o de Estados e Irredutibilidade","text":"<p>Enunciado: Considere uma cadeia de Markov com espa\u00e7o de estados \\(S = \\{1, 2, 3, 4\\}\\) e matriz de transi\u00e7\u00e3o:</p> <p>\\(P = \\begin{pmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0.5 &amp; 0 &amp; 0.5 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0.5 &amp; 0 &amp; 0.5 \\end{pmatrix}\\)</p> <p>Classifique os estados quanto \u00e0 comunica\u00e7\u00e3o e identifique se a cadeia \u00e9 irredut\u00edvel.</p> <p>Resolu\u00e7\u00e3o: 1. Comunica\u00e7\u00e3o: * Do estado \\(1\\), podemos ir para \\(2\\). Do estado \\(2\\), podemos voltar para \\(1\\). Logo, \\(1 \\leftrightarrow 2\\).    * Do estado \\(2\\), podemos ir para \\(3\\). No entanto, o estado \\(3\\) \u00e9 absorvente (\\(P_{33} = 1\\)), ent\u00e3o n\u00e3o podemos sair de \\(3\\). Logo, \\(2 \\to 3\\) mas \\(3 \\not\\to 2\\).    * Do estado \\(4\\), podemos ir para \\(2\\). Como \\(2 \\not\\to 4\\), a comunica\u00e7\u00e3o \u00e9 apenas unidirecional. 2. Classes:    * \\(\\{3\\}\\) \u00e9 uma classe fechada (recorrente).    * \\(\\{1, 2\\}\\) \u00e9 uma classe aberta (transiente), pois h\u00e1 chance de sair para o estado \\(3\\).    * \\(\\{4\\}\\) \u00e9 transiente. 3. Conclus\u00e3o: A cadeia n\u00e3o \u00e9 irredut\u00edvel, pois possui mais de uma classe de comunica\u00e7\u00e3o.</p>"},{"location":"capitulo1/exercicios/#ex12","title":"2. Distribui\u00e7\u00e3o Estacion\u00e1ria","text":"<p>Enunciado: Encontre a distribui\u00e7\u00e3o estacion\u00e1ria \\(\\pi\\) para uma cadeia irredut\u00edvel com matriz:</p> <p>\\(P = \\begin{pmatrix} 0.7 &amp; 0.3 \\\\ 0.4 &amp; 0.6 \\end{pmatrix}\\)</p> <p>Resolu\u00e7\u00e3o: Devemos resolver o sistema \\(\\pi P = \\pi\\) sujeito a \\(\\sum \\pi_i = 1\\). Seja \\(\\pi = (\\pi_1, \\pi_2)\\): 1. \\(0.7\\pi_1 + 0.4\\pi_2 = \\pi_1 \\implies 0.4\\pi_2 = 0.3\\pi_1 \\implies \\pi_1 = \\frac{4}{3}\\pi_2\\) 2. \\(\\pi_1 + \\pi_2 = 1 \\implies \\frac{4}{3}\\pi_2 + \\pi_2 = 1 \\implies \\frac{7}{3}\\pi_2 = 1\\)</p> <p>Resultado: \\(\\pi_2 = \\frac{3}{7}\\) e \\(\\pi_1 = \\frac{4}{7}\\). A distribui\u00e7\u00e3o estacion\u00e1ria \u00e9 \\(\\pi = (\\frac{4}{7}, \\frac{3}{7})\\).</p>"},{"location":"capitulo1/exercicios/#ex13","title":"3. Matriz Fundamental e Absor\u00e7\u00e3o","text":"<p>Enunciado: Para uma cadeia com estados transientes \\(\\{1, 2\\}\\) e estado absorvente \\(\\{3\\}\\), com matriz de transi\u00e7\u00e3o para os transientes \\(Q = \\begin{pmatrix} 0.5 &amp; 0.2 \\\\ 0.1 &amp; 0.4 \\end{pmatrix}\\), calcule o n\u00famero esperado de visitas a cada estado antes da absor\u00e7\u00e3o partindo do estado \\(1\\).</p> <p>Resolu\u00e7\u00e3o: 1. Calcular \\(I - Q\\): \\(I - Q = \\begin{pmatrix} 0.5 &amp; -0.2 \\\\ -0.1 &amp; 0.6 \\end{pmatrix}\\) 2. Matriz Fundamental \\(M = (I - Q)^{-1}\\): \\(\\text{det}(I - Q) = (0.5)(0.6) - (-0.2)(-0.1) = 0.30 - 0.02 = 0.28\\) \\(M = \\frac{1}{0.28} \\begin{pmatrix} 0.6 &amp; 0.2 \\\\ 0.1 &amp; 0.5 \\end{pmatrix} \\approx \\begin{pmatrix} 2.14 &amp; 0.71 \\\\ 0.35 &amp; 1.78 \\end{pmatrix}\\)</p> <p>Interpreta\u00e7\u00e3o: Partindo do estado \\(1\\), espera-se visitar o pr\u00f3prio estado \\(1\\) cerca de \\(2.14\\) vezes e o estado \\(2\\) cerca de \\(0.71\\) vezes antes de ser absorvido pelo estado \\(3\\).</p>"},{"location":"capitulo1/exercicios/#ex14","title":"4. Periodicidade","text":"<p>Enunciado: Determine o per\u00edodo do estado \\(0\\) em uma cadeia com transi\u00e7\u00f5es \\(0 \\to 1 \\to 2 \\to 0\\) e \\(0 \\to 2\\).</p> <p>Resolu\u00e7\u00e3o: 1. Poss\u00edveis caminhos de retorno ao estado \\(0\\):    * \\(0 \\to 1 \\to 2 \\to 0\\) (comprimento \\(3\\))    * \\(0 \\to 2 \\to 0\\) (comprimento \\(2\\)) 2. O per\u00edodo \\(d(0)\\) \u00e9 o m\u00e1ximo divisor comum (\\(mdc\\)) dos comprimentos de todos os caminhos de retorno:    \\(d(0) = mdc(2, 3) = 1\\)</p> <p>Resultado: O estado \u00e9 aperi\u00f3dico.</p>"},{"location":"capitulo1/teoria/","title":"1. Cadeias de Markov: Fundamentos e Estruturas","text":"<p>Este cap\u00edtulo estabelece a \"linguagem\" dos processos estoc\u00e1sticos, definindo o que torna um processo Markoviano e como analisar seu comportamento de longo prazo.</p>"},{"location":"capitulo1/teoria/#11","title":"1. Fundamentos e Defini\u00e7\u00f5es B\u00e1sicas","text":""},{"location":"capitulo1/teoria/#propriedade-de-markov","title":"Propriedade de Markov","text":"<p>A caracter\u00edstica definidora \u00e9 que o futuro do processo depende apenas do estado presente e n\u00e3o do hist\u00f3rico passado. Matematicamente, para um processo \\((X_n)_{n \\geq 0}\\):</p> \\[P(X_{n+1} = j \\mid X_0 = i_0, \\dots, X_n = i) = P(X_{n+1} = j \\mid X_n = i)\\] <ul> <li>Homogeneidade: Assume-se geralmente que as probabilidades de transi\u00e7\u00e3o n\u00e3o mudam com o tempo \\(n\\).</li> <li>Matriz de Transi\u00e7\u00e3o (\\(P\\)): Definimos as entradas como \\(P_{ij} = p(i,j) = P(X_1 = j \\mid X_0 = i)\\). A soma das linhas deve ser sempre 1: \\(\\sum_{j \\in S} p(i,j) = 1\\).</li> <li>Equa\u00e7\u00f5es de Chapman-Kolmogorov: Usadas para calcular a transi\u00e7\u00e3o em \\(n\\) passos. Em termos matriciais: \\(P^{(n)} = P^n\\). A distribui\u00e7\u00e3o no tempo \\(n\\) \u00e9 dada por \\(\\pi_n = \\pi_0 P^n\\).</li> </ul>"},{"location":"capitulo1/teoria/#12","title":"2. Estrutura e Classifica\u00e7\u00e3o de Estados","text":""},{"location":"capitulo1/teoria/#topologia-da-cadeia","title":"Topologia da Cadeia","text":"<ul> <li>Grafo Dirigido: Representa\u00e7\u00e3o visual onde os n\u00f3s s\u00e3o os estados e existe uma aresta \\(i \\to j\\) se \\(P_{ij} &gt; 0\\).</li> <li>Comunica\u00e7\u00e3o (\\(i \\leftrightarrow j\\)): Dois estados se comunicam se for poss\u00edvel ir de \\(i\\) para \\(j\\) e vice-versa em algum n\u00famero de passos.</li> <li>Irredutibilidade: A cadeia \u00e9 irredut\u00edvel se possui apenas uma classe (todos os estados se comunicam).</li> </ul>"},{"location":"capitulo1/teoria/#periodicidade","title":"Periodicidade","text":"<p>O per\u00edodo \\(d(i)\\) \u00e9 o m\u00e1ximo divisor comum (\\(mdc\\)) dos tempos de retorno poss\u00edveis ao estado \\(i\\):</p> \\[d(i) = mdc\\{n \\geq 1 : P_{ii}^{(n)} &gt; 0\\}\\] <ul> <li>Se \\(d(i) = 1\\), o estado \u00e9 aperi\u00f3dico.</li> <li>Se \\(P_{ii} &gt; 0\\) (possui um \"la\u00e7o\" no grafo), o estado \u00e9 automaticamente aperi\u00f3dico.</li> </ul>"},{"location":"capitulo1/teoria/#13","title":"3. An\u00e1lise de Espa\u00e7os de Estados Finitos","text":""},{"location":"capitulo1/teoria/#distribuicao-estacionaria-pi","title":"Distribui\u00e7\u00e3o Estacion\u00e1ria (\\(\\pi\\))","text":"<p>Vetor de probabilidades que permanece inalterado pela din\u00e2mica da cadeia. Resolve-se o sistema:</p> \\[\\pi = \\pi P \\quad \\text{sujeito a} \\quad \\sum \\pi(i) = 1\\]"},{"location":"capitulo1/teoria/#analise-de-transientes-matriz-fundamental","title":"An\u00e1lise de Transientes (Matriz Fundamental)","text":"<p>Para cadeias redut\u00edveis, usamos a forma can\u00f4nica: \\(P = \\begin{pmatrix} P_{\\text{fechada}} &amp; 0 \\\\ R &amp; Q \\end{pmatrix}\\). A Matriz Fundamental \u00e9 dada por:</p> \\[M = (I - Q)^{-1}\\] <ul> <li>A entrada \\(M_{ij}\\) d\u00e1 o n\u00famero esperado de visitas ao estado \\(j\\) come\u00e7ando em \\(i\\).</li> <li>A some da linha \\(i\\) de \\(M\\) fornece o tempo esperado at\u00e9 a absor\u00e7\u00e3o.</li> </ul>"},{"location":"capitulo1/teoria/#4-propriedade-forte-de-markov","title":"4. Propriedade Forte de Markov","text":""},{"location":"capitulo1/teoria/#tempo-de-parada-tau","title":"Tempo de Parada (\\(\\tau\\))","text":"<p>Uma vari\u00e1vel aleat\u00f3ria onde a decis\u00e3o de parar no tempo \\(n\\) depende apenas da hist\u00f3ria at\u00e9 \\(n\\) (\\(X_0, \\dots, X_n\\)).</p> <p>!!! info \"Defini\u00e7\u00e3o\"     A cadeia \"reinicia\" probabilisticamente a partir de um tempo de parada finito, comportando-se como se tivesse come\u00e7ado em \\(X_\\tau\\).</p>"},{"location":"capitulo1/teoria/#14","title":"5. Espa\u00e7os Enumer\u00e1veis e Tipos de Recorr\u00eancia","text":"<ul> <li>Estado Recorrente: Retorno certo (\\(P(\\tau_i &lt; \\infty) = 1\\)). Crit\u00e9rio: \\(\\sum_{n} P_{ii}^{(n)} = \\infty\\).</li> <li>Estado Transiente: Probabilidade positiva de nunca mais voltar. Crit\u00e9rio: \\(\\sum_{n} P_{ii}^{(n)} &lt; \\infty\\).</li> <li>Recorr\u00eancia Positiva: Tempo m\u00e9dio de retorno finito (\\(E[\\tau_i] &lt; \\infty\\)). Existe \\(\\pi(i) = 1/E_i[\\tau_i]\\).</li> <li>Recorr\u00eancia Nula: Retorno certo, mas tempo m\u00e9dio infinito (\\(E[\\tau_i] = \\infty\\)). N\u00e3o existe \\(\\pi\\).</li> </ul>"},{"location":"capitulo1/teoria/#15","title":"6. Reversibilidade","text":""},{"location":"capitulo1/teoria/#balanceamento-detalhado","title":"Balanceamento Detalhado","text":"<p>Uma distribui\u00e7\u00e3o \\(\\pi\\) \u00e9 revers\u00edvel se o fluxo \u00e9 igual em ambas as dire\u00e7\u00f5es:</p> \\[\\pi(i)P_{ij} = \\pi(j)P_{ji}, \\quad \\forall i,j \\in S\\] <p>!!! tip \"Dica\"     Se \\(\\pi\\) satisfaz essa condi\u00e7\u00e3o, ela \u00e9 automaticamente estacion\u00e1ria (\\(\\pi = \\pi P\\)).</p>"},{"location":"capitulo1/teoria/#7-aplicacoes-especificas","title":"7. Aplica\u00e7\u00f5es Espec\u00edficas","text":"<ul> <li>Ru\u00edna do Jogador: Passeio aleat\u00f3rio com barreiras absorventes. Probabilidade de ru\u00edna come\u00e7ando em \\(i\\) (jogo justo): \\(1 - (i/N)\\).</li> <li>Cadeias de Ramifica\u00e7\u00e3o: Se a m\u00e9dia de filhos \\(\\mu &gt; 1\\), a probabilidade de extin\u00e7\u00e3o \u00e9 a menor raiz positiva de \\(s = \\phi(s)\\).</li> <li>MCMC (Metropolis-Hastings): Gera amostras de \\(\\pi\\) complexas usando a probabilidade de aceita\u00e7\u00e3o:   \\(\\alpha(i,j) = \\min\\left(1, \\frac{\\pi(j)q(j,i)}{\\pi(i)q(i,j)}\\right)\\)</li> </ul>"},{"location":"capitulo2/exercicios/","title":"Exerc\u00edcios Resolvidos: Processos de Poisson","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos principais t\u00f3picos abordados no Cap\u00edtulo 2.</p>"},{"location":"capitulo2/exercicios/#ex21","title":"1. Probabilidades de Contagem e Incrementos","text":"<p>Enunciado: Em um servidor de e-mails, as mensagens chegam segundo um processo de Poisson com taxa \\(\\lambda = 10\\) e-mails por hora. Qual a probabilidade de que cheguem exatamente 3 e-mails nos primeiros 20 minutos e nenhum e-mail nos 10 minutos seguintes?</p> <p>Resolu\u00e7\u00e3o: 1. Definir as taxas para cada intervalo:    * O primeiro intervalo \u00e9 de 20 minutos (\\(t_1 = 1/3\\) hora). A m\u00e9dia \u00e9 \\(\\alpha_1 = \\lambda \\cdot t_1 = 10 \\cdot (1/3) = 10/3\\).    * O segundo intervalo \u00e9 de 10 minutos (\\(t_2 = 1/6\\) hora). A m\u00e9dia \u00e9 \\(\\alpha_2 = \\lambda \\cdot t_2 = 10 \\cdot (1/6) = 10/6 = 5/3\\). 2. Calcular as probabilidades independentes:    * Probabilidade de 3 e-mails no primeiro intervalo:      \\(P(N_{1/3} = 3) = \\frac{e^{-10/3} \\cdot (10/3)^3}{3!}\\)    * Probabilidade de 0 e-mails no segundo intervalo:      \\(P(N_{1/2} - N_{1/3} = 0) = e^{-5/3}\\) 3. Resultado Final (Multiplica\u00e7\u00e3o devido aos incrementos independentes): \\(P = \\left( \\frac{e^{-10/3} \\cdot 1000/27}{6} \\right) \\cdot e^{-5/3} = \\frac{1000}{162} \\cdot e^{-5} \\approx 0.0415 \\text{ (ou 4.15%)}\\)</p>"},{"location":"capitulo2/exercicios/#ex22","title":"2. Decomposi\u00e7\u00e3o e Superposi\u00e7\u00e3o (Thinning)","text":"<p>Enunciado: Um call center recebe chamadas t\u00e9cnicas (\\(\\lambda_T = 4/\\text{hora}\\)) e chamadas comerciais (\\(\\lambda_C = 6/\\text{hora}\\)). Sabe-se que \\(20\\%\\) das chamadas t\u00e9cnicas s\u00e3o classificadas como \"urgentes\". Qual a probabilidade de o centro receber mais de 2 chamadas urgentes em um turno de 2 horas?</p> <p>Resolu\u00e7\u00e3o: 1. Identificar a taxa das chamadas urgentes:    A taxa t\u00e9cnica \u00e9 \\(\\lambda_T = 4\\). A taxa de urgentes \u00e9 \\(\\lambda_U = \\lambda_T \\cdot p = 4 \\cdot 0,2 = 0,8\\) chamadas por hora. 2. Ajustar para o intervalo de 2 horas (\\(t=2\\)):    A m\u00e9dia no turno \u00e9 \\(E[N_U(2)] = 0,8 \\cdot 2 = 1,6\\). 3. Calcular \\(P(N_U &gt; 2)\\) usando o complementar: \\(P(N_U &gt; 2) = 1 - [P(N_U = 0) + P(N_U = 1) + P(N_U = 2)]\\) \\(P = 1 - [e^{-1,6} + e^{-1,6} \\cdot 1,6 + \\frac{e^{-1,6} \\cdot (1,6)^2}{2}]\\) \\(P = 1 - e^{-1,6} \\cdot (1 + 1,6 + 1,28) = 1 - 3,88 \\cdot e^{-1,6} \\approx 0,2166 \\text{ (ou 21,66%)}\\)</p>"},{"location":"capitulo2/exercicios/#ex23","title":"3. Tempos de Interchegada e Distribui\u00e7\u00e3o Gama","text":"<p>Enunciado: Falhas em uma rede ocorrem com taxa \\(\\lambda = 0,5\\) falhas/dia. Qual o tempo esperado para que ocorra a 4\u00aa falha e qual a probabilidade de ela ocorrer antes de completar 6 dias?</p> <p>Resolu\u00e7\u00e3o: 1. Tempo Esperado:    O tempo at\u00e9 a \\(n\\)-\u00e9sima renova\u00e7\u00e3o \\(S_n\\) segue uma distribui\u00e7\u00e3o Gama com m\u00e9dia \\(n/\\lambda\\).    \\(E[S_4] = 4 / 0,5 = 8 \\text{ dias}\\) 2. Probabilidade \\(P(S_4 \\leq 6)\\):    Pela rela\u00e7\u00e3o fundamental entre o processo de contagem e os tempos de chegada:    \\(\\{S_4 \\leq 6\\} \\iff \\{N_6 \\geq 4\\}\\) 3. Calcular via Poisson (\\(\\alpha = 0,5 \\cdot 6 = 3\\)): \\(P(N_6 \\geq 4) = 1 - \\sum_{k=0}^{3} \\frac{e^{-3} \\cdot 3^k}{k!}\\) \\(P = 1 - e^{-3} \\cdot (1 + 3 + 4.5 + 4.5) = 1 - 13 \\cdot e^{-3} \\approx 0,3528 \\text{ (ou 35,28%)}\\)</p>"},{"location":"capitulo2/exercicios/#ex24","title":"4. Processo de Poisson Composto","text":"<p>Enunciado: O n\u00famero de clientes que entram em uma loja segue um processo de Poisson com \\(\\lambda = 5/\\text{hora}\\). Cada cliente gasta um valor \\(Y_i\\) que \u00e9 independente e segue uma distribui\u00e7\u00e3o com m\u00e9dia \\(\\$20\\) e desvio padr\u00e3o \\(\\$10\\). Calcule a m\u00e9dia e a vari\u00e2ncia do faturamento total ap\u00f3s 8 horas.</p> <p>Resolu\u00e7\u00e3o: 1. Dados do problema: \\(\\lambda = 5\\), \\(t = 8\\), \\(E[Y] = 20\\), \\(Var(Y) = 10^2 = 100\\).    O n\u00famero m\u00e9dio de clientes \u00e9 \\(E[N_8] = 5 \\cdot 8 = 40\\). 2. M\u00e9dia do Faturamento (\\(X_t\\)): \\(E[X_8] = E[N_8] \\cdot E[Y] = 40 \\cdot 20 = \\$800\\) 3. Vari\u00e2ncia do Faturamento: \\(Var(X_8) = \\lambda t \\cdot E[Y^2]\\)    Primeiro, calculamos \\(E[Y^2] = Var(Y) + (E[Y])^2 = 100 + 400 = 500\\).    \\(Var(X_8) = (5 \\cdot 8) \\cdot 500 = 40 \\cdot 500 = 20.000\\)</p>"},{"location":"capitulo2/teoria/","title":"2. Processos de Poisson e Aplica\u00e7\u00f5es","text":""},{"location":"capitulo2/teoria/#21","title":"1. O Processo de Poisson: Defini\u00e7\u00e3o e Hip\u00f3teses","text":"<p>O processo de Poisson \u00e9 o modelo fundamental para contar ocorr\u00eancias de eventos pontuais e aleat\u00f3rios ao longo do tempo (ex: chamadas num call center, falhas de equipamento, chegada de particules).</p> <ul> <li> <p>Processo de Contagem (\\(N_t\\)): \u00c9 uma fun\u00e7\u00e3o \"escada\" onde \\(N_t\\) representa o n\u00famero de ocorr\u00eancias no intervalo \\((0,t]\\). As hip\u00f3teses fundamentais que definem o processo s\u00e3o:</p> <ol> <li>Incrementos Estacion\u00e1rios (H1): A probabilidade de ocorrerem \\(k\\) eventos num intervalo depende apenas do comprimento do intervalo, n\u00e3o de onde ele come\u00e7a.</li> <li>Incrementos Independentes (H2): O n\u00famero de ocorr\u00eancias em intervalos de tempo disjuntos s\u00e3o vari\u00e1veis aleat\u00f3rias independentes.</li> <li>Ocorr\u00eancias Isoladas (H3): A probabilidade de dois ou mais eventos ocorrerem num intervalo min\u00fasculo \\(h\\) \u00e9 desprez\u00edvel comparada \u00e0 probabilidade de ocorrer apenas um:</li> </ol> <p>\\(\\lim_{h \\to 0} \\frac{P(N_h \\geq 2)}{h} = 0\\)</p> </li> <li> <p>Distribui\u00e7\u00e3o de Poisson: A partir dessas hip\u00f3teses, demonstra-se que o n\u00famero de eventos at\u00e9 o tempo \\(t\\) segue uma distribui\u00e7\u00e3o de Poisson com m\u00e9dia \\(\\lambda t\\), onde \\(\\lambda\\) \u00e9 a taxa do processo:</p> </li> </ul> <p>\\(P(N_t = k) = \\frac{e^{-\\lambda t}(\\lambda t)^k}{k!}, \\quad k=0,1,2,\\dots\\)</p>"},{"location":"capitulo2/teoria/#22","title":"2. A Distribui\u00e7\u00e3o Exponencial e Tempos de Chegada","text":"<p>Esta se\u00e7\u00e3o conecta a contagem discreta (\\(N_t\\)) com o tempo cont\u00ednuo entre os eventos.</p> <ul> <li>Tempo at\u00e9 o primeiro evento (\\(T_1\\)): A probabilidade de n\u00e3o haver eventos at\u00e9 \\(t\\) (\\(N_t=0\\)) \u00e9 \\(e^{-\\lambda t}\\). Isso implica que o tempo de espera tem distribui\u00e7\u00e3o Exponencial:</li> </ul> <p>\\(f(t) = \\lambda e^{-\\lambda t} \\quad \\text{e} \\quad F(t) = 1 - e^{-\\lambda t}\\)</p> <ul> <li>Propriedade da Falta de Mem\u00f3ria: A exponencial \u00e9 a \u00fanica distribui\u00e7\u00e3o cont\u00ednua que satisfaz:</li> </ul> <p>\\(P(T &gt; t+s \\mid T &gt; t) = P(T &gt; s)\\)</p> <p>Significado: O fato de nada ter acontecido at\u00e9 o tempo \\(t\\) n\u00e3o altera a probabilidade do evento ocorrer nos pr\u00f3ximos \\(s\\) minutos. O sistema n\u00e3o \"envelhece\".</p> <ul> <li> <p>M\u00ednimo de Exponenciais: Se \\(T_1, \\dots, T_n\\) s\u00e3o independentes com taxas \\(\\lambda_i\\), o m\u00ednimo deles \u00e9 tamb\u00e9m exponencial com taxa igual \u00e0 soma (\\(\\sum \\lambda_i\\)).</p> </li> <li> <p>Distribui\u00e7\u00e3o Gama: O tempo at\u00e9 o \\(n\\)-\u00e9simo evento (\\(S_n = T_1 + \\dots + T_n\\)) segue uma distribui\u00e7\u00e3o Gama com par\u00e2metros \\(n\\) e \\(\\lambda\\).</p> </li> </ul>"},{"location":"capitulo2/teoria/#23","title":"3. Constru\u00e7\u00e3o Alternativa e Propriedades Avan\u00e7adas","text":"<p>O livro revisita o processo de Poisson construindo-o a partir dos tempos de chegada, em vez das hip\u00f3teses infinitesimais.</p> <ul> <li>Constru\u00e7\u00e3o via Interchegadas: Pode-se definir \\(N_t\\) atrav\u00e9s de uma sequ\u00eancia de vari\u00e1veis i.i.d. \\(T_n \\sim \\text{Exp}(\\lambda)\\).</li> </ul> <p>\\(N_t = \\max\\{n \\geq 0 : S_n \\leq t\\}\\)</p> <p>Onde \\(S_n\\) s\u00e3o os instantes dos eventos.</p> <ul> <li> <p>Superposi\u00e7\u00e3o: A soma de dois processos de Poisson independentes com taxas \\(\\lambda_1\\) e \\(\\lambda_2\\) \u00e9 um novo processo de Poisson com taxa \\(\\lambda_1 + \\lambda_2\\).</p> </li> <li> <p>Decomposi\u00e7\u00e3o (Thinning): Se cada evento de um processo de Poisson (taxa \\(\\lambda\\)) \u00e9 classificado como \"Tipo 1\" (probabilidade \\(p\\)) ou \"Tipo 2\" (probabilidade \\(1-p\\)), os processos resultantes s\u00e3o processos de Poisson independentes com taxas \\(\\lambda p\\) e \\(\\lambda(1-p)\\).</p> </li> <li> <p>Estat\u00edsticas de Ordem (Distribui\u00e7\u00e3o Condicional): Dado que sabemos que ocorreram \\(n\\) eventos at\u00e9 o tempo \\(t\\) (\\(N_t=n\\)), os instantes exatos dessas ocorr\u00eancias (\\(S_1, \\dots, S_n\\)) t\u00eam a mesma distribui\u00e7\u00e3o que \\(n\\) vari\u00e1veis aleat\u00f3rias \\(\\text{Uniforme}(0,t)\\) ordenadas.</p> <ul> <li>Implica\u00e7\u00e3o: Os eventos se espalham \"aleatoriamente\" no intervalo, sem aglomera\u00e7\u00e3o preferencial.</li> </ul> </li> </ul>"},{"location":"capitulo2/teoria/#24","title":"4. Varia\u00e7\u00f5es e Aplica\u00e7\u00f5es do Modelo","text":"<p>O cap\u00edtulo expande o modelo b\u00e1sico para situa\u00e7\u00f5es mais complexas.</p> <ul> <li>Processo de Poisson Composto: Usado quando cada evento tem um \"peso\" ou \"valor\" associado (ex: valor de um sinistro de seguro, tamanho de um pacote de dados).</li> </ul> <p>\\(X_t = \\sum_{i=1}^{N_t} Y_i\\)</p> <p>Onde \\(N_t\\) \u00e9 Poisson e \\(Y_i\\) s\u00e3o i.i.d. e independentes de \\(N\\).     * M\u00e9dia: \\(E[X_t] = E[N_t] E[Y_1] = \\lambda t E[Y_1]\\).     * Vari\u00e2ncia: \\(\\text{Var}(X_t) = \\lambda t E[Y_1^2]\\).</p> <ul> <li>Processo de Poisson N\u00e3o-Homog\u00eaneo: A taxa de ocorr\u00eancia \\(\\lambda\\) n\u00e3o \u00e9 constante, mas uma fun\u00e7\u00e3o do tempo \\(\\lambda(t)\\). O n\u00famero de eventos em \\((t, t+s]\\) segue uma Poisson com m\u00e9dia:</li> </ul> <p>\\(\\int_{t}^{t+s} \\lambda(u) du\\)</p> <ul> <li> <p>Processo Pontual em \\(\\mathbb{R}^d\\): Generaliza\u00e7\u00e3o espacial. O n\u00famero de pontos numa regi\u00e3o \\(A\\) segue uma Poisson proporcional ao volume/\u00e1rea de \\(A\\). Regi\u00f5es disjuntas t\u00eam contagens independentes.</p> </li> <li> <p>Fila \\(M/G/\\infty\\): Um sistema com infinitos servidores (sem espera).</p> <ul> <li>Chegadas: Poisson (\\(\\lambda\\)).</li> <li>Atendimento: Distribui\u00e7\u00e3o Geral \\(G\\).</li> <li>Resultado: O n\u00famero de clientes sendo atendidos no tempo \\(t\\) (\\(X_t\\)) e o n\u00famero de clientes que j\u00e1 sa\u00edram (\\(Y_t\\)) s\u00e3o vari\u00e1veis aleat\u00f3rias independentes, ambas com distribui\u00e7\u00e3o de Poisson.</li> </ul> </li> </ul>"},{"location":"capitulo3/exercicios/","title":"Exerc\u00edcios Resolvidos: Cadeias de Markov em Tempo Cont\u00ednuo","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos t\u00f3picos abordados no Cap\u00edtulo 3, focando em matrizes de intensidade e modelos de filas.</p>"},{"location":"capitulo3/exercicios/#ex31","title":"1. Constru\u00e7\u00e3o da Matriz Geradora (\\(Q\\))","text":"<p>Enunciado: Um sistema pode estar em tr\u00eas estados: Funcionando (1), Alerta (2) e Falha (3). As taxas de transi\u00e7\u00e3o s\u00e3o: de 1 para 2 \u00e9 \\(0.5/\\text{h}\\), de 2 para 1 \u00e9 \\(0.2/\\text{h}\\), de 2 para 3 \u00e9 \\(0.8/\\text{h}\\) e de 3 para 1 \u00e9 \\(1.0/\\text{h}\\). Monte a matriz geradora \\(Q\\).</p> <p>Resolu\u00e7\u00e3o: Lembrando que as entradas fora da diagonal s\u00e3o as taxas \\(q_{ij}\\) e as entradas da diagonal s\u00e3o \\(q_{ii} = -\\sum_{j \\neq i} q_{ij}\\).</p> <ol> <li>Taxas de sa\u00edda:</li> <li>Do estado 1: \\(\\lambda_1 = q_{12} = 0.5 \\implies q_{11} = -0.5\\).</li> <li>Do estado 2: \\(\\lambda_2 = q_{21} + q_{23} = 0.2 + 0.8 = 1.0 \\implies q_{22} = -1.0\\).</li> <li>Do estado 3: \\(\\lambda_3 = q_{31} = 1.0 \\implies q_{33} = -1.0\\).</li> </ol> <p>Resultado: \\(Q = \\begin{pmatrix} -0.5 &amp; 0.5 &amp; 0 \\\\ 0.2 &amp; -1.0 &amp; 0.8 \\\\ 1.0 &amp; 0 &amp; -1.0 \\end{pmatrix}\\)</p>"},{"location":"capitulo3/exercicios/#ex32","title":"2. Distribui\u00e7\u00e3o Estacion\u00e1ria (\\(\\pi\\)) em Tempo Cont\u00ednuo","text":"<p>Enunciado: Calcule a distribui\u00e7\u00e3o estacion\u00e1ria para a matriz geradora: \\(Q = \\begin{pmatrix} -2 &amp; 2 \\\\ 3 &amp; -3 \\end{pmatrix}\\)</p> <p>Resolu\u00e7\u00e3o: Resolvemos o sistema \\(\\pi Q = 0\\) com \\(\\pi_1 + \\pi_2 = 1\\). 1. \\(-2\\pi_1 + 3\\pi_2 = 0 \\implies 3\\pi_2 = 2\\pi_1 \\implies \\pi_1 = 1.5\\pi_2\\). 2. \\(1.5\\pi_2 + \\pi_2 = 1 \\implies 2.5\\pi_2 = 1 \\implies \\pi_2 = 0.4\\). 3. \\(\\pi_1 = 1 - 0.4 = 0.6\\).</p> <p>Resultado: \\(\\pi = (0.6, 0.4)\\).</p>"},{"location":"capitulo3/exercicios/#ex33","title":"3. Filas M/M/1: Equil\u00edbrio e Performance","text":"<p>Enunciado: Clientes chegam a um guich\u00ea (M/M/1) com taxa \\(\\beta = 4/\\text{h}\\) e s\u00e3o atendidos com taxa \\(\\mu = 5/\\text{h}\\). Calcule a probabilidade de o guich\u00ea estar vazio e o n\u00famero m\u00e9dio de clientes no sistema.</p> <p>Resolu\u00e7\u00e3o: 1. Fator de utiliza\u00e7\u00e3o (\\(\\rho\\)): \\(\\rho = \\beta/\\mu = 4/5 = 0.8\\). 2. Probabilidade de estar vazio (\\(\\pi_0\\)): \\(\\pi_0 = 1 - \\rho = 1 - 0.8 = 0.2 \\text{ (ou 20%)}\\). 3. N\u00famero m\u00e9dio de clientes (\\(L\\)): \\(L = \\rho / (1 - \\rho) = 0.8 / 0.2 = 4\\) clientes.</p>"},{"location":"capitulo3/exercicios/#ex34","title":"4. Cadeia Imersa e Probabilidades de Salto","text":"<p>Enunciado: Dada a matriz \\(Q\\) do Exerc\u00edcio 1, qual a probabilidade de o sistema, ao sair do estado de Alerta (2), ir para o estado de Falha (3)?</p> <p>Resolu\u00e7\u00e3o: Na cadeia imersa, as probabilidades de transi\u00e7\u00e3o s\u00e3o dadas por \\(\\tilde{p}_{ij} = q_{ij} / \\lambda_i\\). 1. Taxa total de sa\u00edda do estado 2: \\(\\lambda_2 = 1.0\\). 2. Taxa de 2 para 3: \\(q_{23} = 0.8\\). 3. \\(\\tilde{p}_{23} = 0.8 / 1.0 = 0.8\\).</p> <p>Resultado: A probabilidade \u00e9 de \\(80\\%\\).</p>"},{"location":"capitulo3/teoria/","title":"3. Cadeias de Markov em Tempo Cont\u00ednuo","text":""},{"location":"capitulo3/teoria/#31","title":"1. O Modelo: Defini\u00e7\u00f5es e Propriedades B\u00e1sicas","text":"<p>Diferente do tempo discreto, aqui o processo \\((X_t : t \\geq 0)\\) evolui continuamente. A transi\u00e7\u00e3o entre estados pode ocorrer em qualquer instante \\(t\\).</p> <ul> <li>Propriedade de Markov: O futuro do processo depende apenas do estado presente e n\u00e3o do passado. Formalmente, para quaisquer \\(0 \\leq s_1 &lt; \\dots &lt; s_k &lt; s &lt; t\\):</li> </ul> <p>\\(P(X_{s+t} = j \\mid X_s = i, X_{s_k} = i_k, \\dots) = P(X_t = j \\mid X_0 = i) =: P_{i,j}(t)\\)</p> <ul> <li> <p>Homogeneidade: Assume-se que a probabilidade de transi\u00e7\u00e3o \\(P_{i,j}(t)\\) depende apenas do intervalo de tempo \\(t\\), e n\u00e3o do momento absoluto em que a transi\u00e7\u00e3o ocorre.</p> </li> <li> <p>Equa\u00e7\u00f5es de Chapman-Kolmogorov: A probabilidade de ir de \\(i\\) para \\(j\\) no tempo \\(t+s\\) pode ser decomposta passando por um estado intermedi\u00e1rio \\(k\\) no tempo \\(t\\):</p> </li> </ul> <p>\\(P(t+s) = P(t)P(s)\\)</p> <p>Onde \\(P(t)\\) \u00e9 a matriz de probabilidades de transi\u00e7\u00e3o.</p>"},{"location":"capitulo3/teoria/#32","title":"2. Constru\u00e7\u00e3o e Caracter\u00edsticas Infinitesimais","text":"<p>Esta se\u00e7\u00e3o explica como o processo se comporta em intervalos de tempo muito pequenos (\\(h \\to 0\\)), definindo a \"velocidade\" das mudan\u00e7as.</p> <ul> <li>Taxas de Salto (\\(q(i,j)\\)): Representa a taxa com que o processo salta do estado \\(i\\) para o estado \\(j\\).</li> </ul> <p>\\(\\lim_{h \\downarrow 0} \\frac{P_{i,j}(h)}{h} = q(i,j), \\text{ para } i \\neq j\\)</p> <ul> <li>Taxa Total de Sa\u00edda (\\(\\lambda_i\\)): \u00c9 a taxa total com que o processo deixa o estado \\(i\\).</li> </ul> <p>\\(\\lambda_i = \\sum_{j \\neq i} q(i,j)\\)</p> <ul> <li>Matriz Geradora (\\(Q\\)): \u00c9 a matriz fundamental para descrever a din\u00e2mica em tempo cont\u00ednuo (an\u00e1loga \u00e0 matriz \\(P\\) do tempo discreto, mas contendo taxas, n\u00e3o probabilidades).<ul> <li>Entradas fora da diagonal: \\(Q_{i,j} = q(i,j) \\geq 0\\).</li> <li>Entradas na diagonal: \\(Q_{i,i} = -\\lambda_i\\).</li> <li>Soma das linhas: A soma de cada linha \u00e9 zero: \\(\\sum_{j} Q_{i,j} = 0\\).</li> </ul> </li> </ul>"},{"location":"capitulo3/teoria/#33","title":"3. A Cadeia Imersa e Tempos de Espera","text":"<p>Uma forma intuitiva de construir e simular esses processos \u00e9 separar \"onde\" ele salta de \"quando\" ele salta.</p> <ul> <li>Tempos de Espera (Holding Times): O tempo que o processo permanece no estado \\(i\\) antes de mudar segue uma distribui\u00e7\u00e3o Exponencial com par\u00e2metro \\(\\lambda_i\\).</li> <li>Cadeia Imersa (Embedded Chain): \u00c9 uma cadeia de Markov em tempo discreto (\\(\\tilde{Z}_n\\)) que descreve apenas a sequ\u00eancia de estados visitados, ignorando o tempo. A probabilidade de transi\u00e7\u00e3o da cadeia imersa \u00e9:</li> </ul> <p>\\(\\tilde{p}(i,j) = \\frac{q(i,j)}{\\lambda_i}, \\text{ para } i \\neq j\\)</p> <ul> <li>Condi\u00e7\u00e3o de Regularidade: Para garantir que o processo seja bem definido em todo \\(t \\geq 0\\), n\u00e3o podem ocorrer infinitos saltos em tempo finito (explos\u00f5es).</li> </ul>"},{"location":"capitulo3/teoria/#34","title":"4. Equa\u00e7\u00f5es de Kolmogorov","text":"<p>Estas s\u00e3o as equa\u00e7\u00f5es diferenciais que relacionam a matriz geradora \\(Q\\) com as probabilidades de transi\u00e7\u00e3o \\(P(t)\\).</p> <ul> <li>Equa\u00e7\u00e3o Retrospectiva (Backward): Deriva-se condicionando no primeiro salto a partir do estado inicial:</li> </ul> <p>\\(P'(t) = QP(t)\\)</p> <ul> <li>Equa\u00e7\u00e3o Prospectiva (Forward): Deriva-se condicionando no \u00faltimo salto antes do tempo \\(t\\):</li> </ul> <p>\\(P'(t) = P(t)Q\\)</p> <ul> <li>Solu\u00e7\u00e3o Formal: Para espa\u00e7os de estados finitos, a solu\u00e7\u00e3o \u00e9 dada pela exponencial matricial:</li> </ul> <p>\\(P(t) = e^{tQ} = \\sum_{n=0}^{\\infty} \\frac{(tQ)^n}{n!}\\)</p>"},{"location":"capitulo3/teoria/#35","title":"5. Comportamento Assint\u00f3tico (Longo Prazo)","text":"<p>Analisa o que acontece quando \\(t \\to \\infty\\).</p> <ul> <li>Distribui\u00e7\u00e3o Estacion\u00e1ria (\\(\\pi\\)): Verificado resolvendo o sistema linear:</li> </ul> <p>\\(\\pi Q = 0 \\text{ sujeito a } \\sum \\pi(i) = 1\\)</p> <p>Interpreta\u00e7\u00e3o: O fluxo total de probabilidade saindo de cada estado deve ser igual ao fluxo total entrando nele.</p> <ul> <li>Teorema do Limite: Se a cadeia for irredut\u00edvel e positiva recorrente, a probabilidade de estar no estado \\(j\\) converge para \\(\\pi(j)\\), independentemente do estado inicial:</li> </ul> <p>\\(\\lim_{t \\to \\infty} P_{i,j}(t) = \\pi(j)\\)</p> <ul> <li>Rela\u00e7\u00e3o com Tempos de Retorno: \\(\\pi(i) = \\frac{1}{\\lambda_i E_i[T_i]}\\), onde \\(E_i[T_i]\\) \u00e9 o tempo m\u00e9dio de retorno ao estado \\(i\\).</li> </ul>"},{"location":"capitulo3/teoria/#36","title":"6. Reversibilidade","text":"<ul> <li>Equa\u00e7\u00f5es de Balanceamento Detalhado: Uma distribui\u00e7\u00e3o \\(\\pi\\) \u00e9 revers\u00edvel se o fluxo entre quaisquer dois estados \\(i\\) e \\(j\\) \u00e9 equilibrado:</li> </ul> <p>\\(\\pi(i)q(i,j) = \\pi(j)q(j,i)\\)</p> <p>!!! tip \"Dica\"     Se uma distribui\u00e7\u00e3o satisfaz essa condi\u00e7\u00e3o, ela \u00e9 automaticamente estacion\u00e1ria. Isso \u00e9 muito \u00fatil em filas e redes.</p>"},{"location":"capitulo3/teoria/#37","title":"7. Cadeias de Nascimentos e Mortes","text":"<p>Um caso especial onde as transi\u00e7\u00f5es s\u00f3 ocorrem para estados vizinhos (\\(i \\to i+1\\) ou \\(i \\to i-1\\)).</p> <ul> <li>Taxas:<ul> <li>\\(\\beta_i\\): Taxa de nascimento (ida de \\(i\\) para \\(i+1\\)).</li> <li>\\(\\mu_i\\): Taxa de morte (ida de \\(i\\) para \\(i-1\\)).</li> </ul> </li> <li>Solu\u00e7\u00e3o Estacion\u00e1ria: Existe uma f\u00f3rmula fechada para \\(\\pi\\):</li> </ul> <p>\\(\\pi(n) = \\pi(0) \\prod_{k=1}^{n} \\frac{\\beta_{k-1}}{\\mu_k}\\)</p>"},{"location":"capitulo3/teoria/#38","title":"8. Aplica\u00e7\u00f5es: Filas Markovianas","text":"<p>O cap\u00edtulo aplica a teoria de Nascimentos e Mortes para modelar sistemas de filas.</p> <ul> <li>Fila M/M/1: Chegadas Poisson (\\(\\beta\\)), atendimento Exponencial (\\(\\mu\\)), 1 servidor.<ul> <li>Est\u00e1vel se \\(\\beta &lt; \\mu\\).</li> <li>Distribui\u00e7\u00e3o do n\u00famero de clientes \u00e9 Geom\u00e9trica.</li> </ul> </li> <li>Fila M/M/\\(\\infty\\): Infinitos servidores (sem espera). O n\u00famero de clientes no sistema segue uma distribui\u00e7\u00e3o de Poisson.</li> <li>Teorema de Burke: Para uma fila M/M/k est\u00e1vel em equil\u00edbrio, o processo de sa\u00eddas (clientes deixando o sistema) \u00e9 um Processo de Poisson com a mesma taxa das chegadas.</li> </ul>"},{"location":"capitulo4/exercicios/","title":"Exerc\u00edcios Resolvidos: Processos de Renova\u00e7\u00e3o","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos principais t\u00f3picos abordados no Cap\u00edtulo 4.</p>"},{"location":"capitulo4/exercicios/#ex41","title":"1. Instantes de Renova\u00e7\u00e3o e Contagem","text":"<p>Enunciado: Os tempos entre as falhas de um motor seguem uma distribui\u00e7\u00e3o Uniforme no intervalo \\([4, 6]\\) meses. Calcule o tempo m\u00e9dio at\u00e9 a 10\u00aa falha e a taxa de renova\u00e7\u00e3o a longo prazo.</p> <p>Resolu\u00e7\u00e3o: 1. Identificar a m\u00e9dia (\\(\\mu\\)):    Para \\(T \\sim U(4, 6)\\), a m\u00e9dia \u00e9 \\(\\mu = \\frac{4 + 6}{2} = 5\\) meses. 2. Tempo at\u00e9 a 10\u00aa renova\u00e7\u00e3o (\\(S_{10}\\)): \\(E[S_{10}] = 10 \\cdot \\mu = 10 \\cdot 5 = 50\\) meses. 3. Taxa de Renova\u00e7\u00e3o a longo prazo:    Pela Lei Forte dos Grandes N\u00fameros para renova\u00e7\u00e3o:    \\(\\frac{N_t}{t} \\to \\frac{1}{\\mu} = \\frac{1}{5} = 0,2\\) falhas por m\u00eas.</p>"},{"location":"capitulo4/exercicios/#ex42","title":"2. Paradoxo da Inspe\u00e7\u00e3o e Vida Residual","text":"<p>Enunciado: L\u00e2mpadas t\u00eam tempo de vida distribu\u00eddo de forma Exponencial com m\u00e9dia de 100 horas. Se um inspetor chega ao laborat\u00f3rio em um tempo \\(t\\) muito grande, qual o tempo m\u00e9dio de vida total da l\u00e2mpada que ele encontrar\u00e1 instalada (\\(E[C_{\\infty}]\\))?</p> <p>Resolu\u00e7\u00e3o: 1. Dados da distribui\u00e7\u00e3o original: \\(\\mu = 100\\). Para a distribui\u00e7\u00e3o Exponencial, \\(E[T^2] = 2\\mu^2 = 2(100)^2 = 20.000\\). 2. Aplicar a f\u00f3rmula do Paradoxo da Inspe\u00e7\u00e3o:    A vida total limite \u00e9 dada por \\(E[C_{\\infty}] = \\frac{E[T^2]}{E[T]}\\).    \\(E[C_{\\infty}] = \\frac{20.000}{100} = 200\\) horas.</p> <p>Interpreta\u00e7\u00e3o: O inspetor encontrar\u00e1 uma l\u00e2mpada que dura, em m\u00e9dia, o dobro do tempo das l\u00e2mpadas comuns, pois intervalos maiores t\u00eam mais chance de \"cobrir\" o instante da inspe\u00e7\u00e3o.</p>"},{"location":"capitulo4/exercicios/#ex43","title":"3. Distribui\u00e7\u00e3o da Idade (\\(A_t\\)) e Vida Residual (\\(B_t\\))","text":"<p>Enunciado: Considere um processo de renova\u00e7\u00e3o onde os tempos entre eventos s\u00e3o uniformes entre \\(0\\) e \\(2\\). Determine a densidade de probabilidade da vida residual limite (\\(B_{\\infty}\\)).</p> <p>Resolu\u00e7\u00e3o: 1. Dados: \\(f(x) = \\frac{1}{2}\\) para \\(0 \\leq x \\leq 2\\). \\(\\mu = 1\\). 2. F\u00f3rmula da densidade limite: \\(g_{B_{\\infty}}(x) = \\frac{1-F(x)}{\\mu}\\). 3. Calcular \\(1-F(x)\\): \\(F(x) = \\frac{x}{2} \\implies 1-F(x) = 1 - \\frac{x}{2}\\) para \\(0 \\leq x \\leq 2\\). 4. Substituir: \\(g_{B_{\\infty}}(x) = \\frac{1 - x/2}{1} = 1 - \\frac{x}{2}\\).</p> <p>Resultado: A densidade da vida residual decai linearmente de \\(1\\) at\u00e9 \\(0\\) no intervalo \\([0, 2]\\).</p>"},{"location":"capitulo4/exercicios/#ex44","title":"4. Fun\u00e7\u00e3o de Renova\u00e7\u00e3o e Equa\u00e7\u00e3o de Renova\u00e7\u00e3o","text":"<p>Enunciado: Se a fun\u00e7\u00e3o de renova\u00e7\u00e3o \u00e9 dada por \\(U(t) = 1 + 2t\\), qual a m\u00e9dia \\(\\mu\\) dos tempos entre renova\u00e7\u00f5es?</p> <p>Resolu\u00e7\u00e3o: 1. Pelo Teorema Elementar da Renova\u00e7\u00e3o:    \\(\\lim_{t \\to \\infty} \\frac{U(t)}{t} = \\frac{1}{\\mu}\\). 2. Derivando a fun\u00e7\u00e3o dada ou observando o coeficiente angular:    \\(\\frac{1}{\\mu} = 2 \\implies \\mu = 0,5\\).</p> <p>Resultado: O tempo m\u00e9dio entre as renova\u00e7\u00f5es \u00e9 \\(0,5\\) unidades de tempo.</p>"},{"location":"capitulo4/teoria/","title":"4. Processos de Renova\u00e7\u00e3o","text":""},{"location":"capitulo4/teoria/#41","title":"1. Defini\u00e7\u00f5es Fundamentais e Constru\u00e7\u00e3o","text":"<p>A base do modelo \u00e9 a substitui\u00e7\u00e3o da propriedade de \"falta de mem\u00f3ria\" (exponencial) por uma estrutura onde o processo \"recome\u00e7a\" probabilisticamente a cada evento.</p> <ul> <li>Tempos entre Renova\u00e7\u00f5es (\\(T_n\\)): Sequ\u00eancia de vari\u00e1veis aleat\u00f3rias i.i.d. n\u00e3o negativas com fun\u00e7\u00e3o de distribui\u00e7\u00e3o \\(F\\). Assumimos \\(P(T_1 = 0) &lt; 1\\) para evitar degenera\u00e7\u00e3o.<ul> <li>Interpreta\u00e7\u00e3o: \\(T_n\\) \u00e9 o tempo de vida do \\(n\\)-\u00e9simo componente ou o tempo entre ocorr\u00eancias.</li> <li>M\u00e9dia: \\(\\mu = E[T_1] \\in (0, \\infty]\\).</li> </ul> </li> <li>Instantes das Renova\u00e7\u00f5es (\\(S_n\\)): Tempo absoluto da \\(n\\)-\u00e9sima renova\u00e7\u00e3o:</li> </ul> <p>\\(S_0 = 0 \\quad \\text{e} \\quad S_n = \\sum_{i=1}^{n} T_i, \\quad n \\geq 1\\)</p> <ul> <li>Processo de Contagem (\\(N_t\\)): N\u00famero de renova\u00e7\u00f5es at\u00e9 o tempo \\(t\\):</li> </ul> <p>\\(N_t = \\max\\{n \\geq 0 : S_n \\leq t\\}\\)</p> <p>Rela\u00e7\u00e3o Fundamental: \\(\\{N_t \\geq n\\} \\iff \\{S_n \\leq t\\}\\).</p>"},{"location":"capitulo4/teoria/#42","title":"2. Teoremas de Renova\u00e7\u00e3o (Longo Prazo)","text":"<p>Estes teoremas descrevem a estabilidade do processo quando \\(t \\to \\infty\\).</p> <ul> <li>Lei Forte dos Grandes N\u00fameros: A taxa de renova\u00e7\u00f5es converge quase certamente:</li> </ul> <p>\\(\\lim_{t \\to \\infty} \\frac{N_t}{t} = \\frac{1}{\\mu} \\quad \\text{q.c.}\\)</p> <ul> <li>Fun\u00e7\u00e3o de Renova\u00e7\u00e3o (\\(U(t)\\)): N\u00famero esperado de renova\u00e7\u00f5es em \\([0,t]\\):</li> </ul> <p>\\(U(t) = 1 + E[N_t] = \\sum_{n=0}^{\\infty} F^{(n)}(t)\\)</p> <p>Onde \\(F^{(n)}\\) \u00e9 a convolu\u00e7\u00e3o de \\(F\\) consigo mesma \\(n\\) vezes.</p> <ul> <li>Teorema de Blackwell: * Caso N\u00e3o-Aritm\u00e9tico: \\(\\lim_{t \\to \\infty} (U(t+r) - U(t)) = \\frac{r}{\\mu}\\).</li> <li>Teorema do Limite Central: Se \\(\\text{Var}(T_1) = \\sigma^2 &lt; \\infty\\), ent\u00e3o \\(N_t\\) \u00e9 assintoticamente Normal.</li> </ul>"},{"location":"capitulo4/teoria/#43","title":"3. A \"Trindade\": Idade, Vida Residual e Vida Total","text":"<p>Em um instante \\(t\\), o estado do componente \u00e9 descrito por tr\u00eas vari\u00e1veis interligadas:</p> <ol> <li>Idade (\\(A_t\\)): Tempo transcorrido desde a \u00faltima renova\u00e7\u00e3o: \\(A_t = t - S_{N_t}\\).</li> <li>Tempo de Vida Residual (\\(B_t\\)): Tempo at\u00e9 a pr\u00f3xima renova\u00e7\u00e3o: \\(B_t = S_{N_t+1} - t\\).</li> <li>Tempo de Vida Total (\\(C_t\\)): Comprimento do intervalo que cont\u00e9m \\(t\\): \\(C_t = A_t + B_t = T_{N_t+1}\\).</li> </ol>"},{"location":"capitulo4/teoria/#o-paradoxo-da-inspecao","title":"O Paradoxo da Inspe\u00e7\u00e3o","text":"<p>A densidade limite de \\(C_t\\) \u00e9 enviesada pelo tamanho (length-biased):</p> <p>\\(f_{C_{\\infty}}(x) = \\frac{x f(x)}{\\mu}\\)</p> <p>Consequ\u00eancia: O tempo m\u00e9dio de vida inspecionado em tempo aleat\u00f3rio \u00e9 maior que o m\u00e9dio real (\\(E[C_{\\infty}] &gt; E[T]\\)).</p>"},{"location":"capitulo4/teoria/#44","title":"4. Equa\u00e7\u00e3o de Renova\u00e7\u00e3o","text":"<p>Ferramenta anal\u00edtica central para provar resultados assint\u00f3ticos:</p> <p>\\(\\phi(t) = h(t) + \\int_{0}^{t} \\phi(t-s) dF(s)\\)</p> <p>A solu\u00e7\u00e3o \u00fanica \u00e9 dada pela convolu\u00e7\u00e3o com a fun\u00e7\u00e3o de renova\u00e7\u00e3o \\(U\\):</p> <p>\\(\\phi(t) = \\int_{0}^{t} h(t-s) dU(s)\\)</p>"},{"location":"capitulo4/teoria/#45","title":"5. Processos de Renova\u00e7\u00e3o com Atraso (Delayed)","text":"<p>Ocorre quando o primeiro tempo \\(T_0\\) tem distribui\u00e7\u00e3o \\(G \\neq F\\).</p> <ul> <li>Processo Estacion\u00e1rio: Se \\(G\\) for a distribui\u00e7\u00e3o de equil\u00edbrio:</li> </ul> <p>\\(G(x) = \\frac{1}{\\mu} \\int_{0}^{x} (1 - F(s)) ds\\)</p> <p>Ent\u00e3o o processo torna-se estacion\u00e1rio e \\(E[N_t] = \\frac{t}{\\mu}\\).</p>"},{"location":"capitulo4/teoria/#46","title":"6. Aplica\u00e7\u00f5es","text":"<ul> <li>Fila M/G/1: Os instantes em que a fila fica vazia formam um processo de renova\u00e7\u00e3o.</li> </ul> <p>\\(\\text{Propor\u00e7\u00e3o Ocupada} = \\frac{E[U_1]}{E[R_1] + E[U_1]} = \\lambda \\theta\\)</p> <p>Onde \\(R_1\\) \u00e9 o tempo ocioso e \\(U_1\\) o tempo ocupado.</p> <ul> <li>Contador Geiger Tipo II: O n\u00famero de registros de pulsos \u00e9 modelado como um processo de renova\u00e7\u00e3o devido ao \"tempo morto\".</li> </ul>"},{"location":"capitulo5/exercicios/","title":"Exerc\u00edcios Resolvidos: Martingales","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos principais t\u00f3picos abordados no Cap\u00edtulo 5.</p>"},{"location":"capitulo5/exercicios/#ex51","title":"1. Verifica\u00e7\u00e3o da Propriedade de Martingale","text":"<p>Enunciado: Seja \\(X_n\\) um processo onde \\(X_{n+1}\\) \u00e9 igual a \\(2X_n\\) com probabilidade \\(0.5\\) e igual a \\(0\\) com probabilidade \\(0.5\\). Verifique se \\(X_n\\) \u00e9 um martingale em rela\u00e7\u00e3o \u00e0 sua pr\u00f3pria filtra\u00e7\u00e3o.</p> <p>Resolu\u00e7\u00e3o: Para ser um martingale, deve satisfazer \\(E[X_{n+1} \\mid X_0, \\dots, X_n] = X_n\\). 1. Calculamos a esperan\u00e7a condicional:    \\(E[X_{n+1} \\mid X_n] = (2X_n) \\cdot 0.5 + (0) \\cdot 0.5\\) \\(E[X_{n+1} \\mid X_n] = X_n\\) 2. Conclus\u00e3o: Como a esperan\u00e7a do pr\u00f3ximo passo, dado o presente, \u00e9 igual ao valor atual, o processo \u00e9 um martingale.</p>"},{"location":"capitulo5/exercicios/#ex52","title":"2. Ru\u00edna do Jogador via Amostragem Opcional","text":"<p>Enunciado: Um jogador come\u00e7a com \\(\\$k\\) e aposta \\(\\$1\\) em cada rodada (ganha \\(\\$1\\) ou perde \\(\\$1\\) com prob. \\(0.5\\)). Ele para se atingir \\(\\$N\\) ou se chegar a \\(\\$0\\). Qual a probabilidade de ele sair vitorioso com \\(\\$N\\)?</p> <p>Resolu\u00e7\u00e3o: 1. Seja \\(M_n\\) o capital no tempo \\(n\\). \\(M_n\\) \u00e9 um martingale e o tempo de parada \\(\\tau\\) (atingir \\(0\\) ou \\(N\\)) \u00e9 finito. 2. Pelo Teorema da Amostragem Opcional: \\(E[M_\\tau] = E[M_0] = k\\). 3. Seja \\(p\\) a probabilidade de atingir \\(N\\). Ent\u00e3o:    \\(E[M_\\tau] = N \\cdot p + 0 \\cdot (1-p) = k\\) \\(Np = k \\implies p = \\frac{k}{N}\\)</p> <p>Resultado: A probabilidade de vit\u00f3ria \u00e9 \\(\\frac{k}{N}\\).</p>"},{"location":"capitulo5/exercicios/#ex53","title":"3. Martingale Quadr\u00e1tico e Tempo de Espera","text":"<p>Enunciado: No problema anterior, qual o tempo m\u00e9dio esperado \\(E[\\tau]\\) para o jogo terminar?</p> <p>Resolu\u00e7\u00e3o: 1. Sabemos que \\(M_n^2 - n\\) \u00e9 um martingale (martingale quadr\u00e1tico para passos de vari\u00e2ncia \\(1\\)). 2. Pelo Teorema da Amostragem Opcional: \\(E[M_\\tau^2 - \\tau] = E[M_0^2 - 0] = k^2\\). 3. \\(E[M_\\tau^2] - E[\\tau] = k^2\\). 4. Calculamos \\(E[M_\\tau^2]\\) usando a probabilidade \\(p = k/N\\) do exerc\u00edcio anterior:    \\(E[M_\\tau^2] = N^2 \\cdot (k/N) + 0^2 \\cdot (1 - k/N) = Nk\\). 5. Substituindo: \\(Nk - E[\\tau] = k^2 \\implies E[\\tau] = Nk - k^2 = k(N-k)\\).</p> <p>Resultado: O tempo m\u00e9dio \u00e9 \\(k(N-k)\\) rodadas.</p>"},{"location":"capitulo5/exercicios/#ex54","title":"4. Desigualdade de Azuma-Hoeffding","text":"<p>Enunciado: Um martingale \\(M_n\\) tem incrementos limitados por \\(|M_n - M_{n-1}| \\leq 1\\). Se \\(M_0 = 0\\), estime a probabilidade de \\(M_{100}\\) ser maior ou igual a \\(20\\).</p> <p>Resolu\u00e7\u00e3o: 1. Usamos a f\u00f3rmula: \\(P(M_n - M_0 \\geq \\lambda) \\leq \\exp\\left(-\\frac{\\lambda^2}{2\\sum c_i^2}\\right)\\). 2. Aqui, \\(n=100\\), \\(\\lambda=20\\) e \\(c_i=1\\) para todos os \\(i\\). 3. \\(\\sum_{i=1}^{100} c_i^2 = 100\\). 4. \\(P(M_{100} \\geq 20) \\leq \\exp\\left(-\\frac{20^2}{2 \\cdot 100}\\right) = \\exp\\left(-\\frac{400}{200}\\right) = e^{-2} \\approx 0.1353\\).</p> <p>Resultado: A probabilidade \u00e9 de no m\u00e1ximo \\(13.53\\%\\).</p>"},{"location":"capitulo5/teoria/","title":"5. Martingales","text":""},{"location":"capitulo5/teoria/#51","title":"1. Defini\u00e7\u00f5es Fundamentais e Estrutura","text":"<p>O conceito de Martingale formaliza a ideia de um \"jogo justo\", onde o conhecimento do passado n\u00e3o ajuda a prever a mudan\u00e7a futura m\u00e9dia.</p> <ul> <li>Filtra\u00e7\u00e3o (\\(A_n\\)): \u00c9 uma sequ\u00eancia crescente de \\(\\sigma\\)-\u00e1lgebras (\\(A_0 \\subset A_1 \\subset \\dots \\subset A\\)). Representa o ac\u00famulo de informa\u00e7\u00e3o ao longo do tempo.</li> <li> <p>Martingale: Um processo estoc\u00e1stico (\\(M_n : n \\geq 0\\)) \u00e9 um martingale com respeito a uma filtra\u00e7\u00e3o (\\(A_n\\)) se satisfaz:</p> <ol> <li>Integrabilidade: \\(E[|M_n|] &lt; \\infty\\) para todo \\(n\\).</li> <li>Adaptabilidade: \\(M_n\\) \u00e9 \\(A_n\\)-mensur\u00e1vel.</li> <li>Propriedade de Martingale: \\(E[M_{n+1} \\mid A_n] = M_n\\) quase certamente.</li> <li>Consequ\u00eancia: \\(E[M_n] = E[M_0]\\) para todo \\(n\\).</li> </ol> </li> <li> <p>Submartingale: Tem tend\u00eancia de crescer (ou manter-se): \\(E[X_{n+1} \\mid A_n] \\geq X_n\\).</p> </li> <li>Supermartingale: Tem tend\u00eancia de decrescer (ou manter-se): \\(E[X_{n+1} \\mid A_n] \\leq X_n\\).</li> </ul>"},{"location":"capitulo5/teoria/#52","title":"2. Exemplos Cl\u00e1ssicos","text":"<ul> <li>Soma de Vari\u00e1veis i.i.d.: Se \\(S_n = \\sum_{i=1}^{n} \\xi_i\\) com \\(E[\\xi_i] = \\mu\\), ent\u00e3o \\(M_n = S_n - n\\mu\\) \u00e9 um martingale.</li> <li>Martingale Quadr\u00e1tico: Se \\(E[\\xi_i] = 0\\) e \\(\\text{Var}(\\xi_i) = \\sigma^2\\), ent\u00e3o \\(M_n = S_n^2 - n\\sigma^2\\) \u00e9 um martingale.</li> <li>Urna de Polya: A propor\u00e7\u00e3o de bolas brancas \\(M_n = \\frac{X_n}{n+2}\\) \u00e9 um martingale e converge para uma vari\u00e1vel aleat\u00f3ria.</li> <li>Fun\u00e7\u00f5es Harm\u00f4nicas: Se \\(Ph = h\\), ent\u00e3o \\(M_n = h(X_n)\\) \u00e9 um martingale.</li> </ul>"},{"location":"capitulo5/teoria/#53","title":"3. Tempos de Parada e Amostragem Opcional","text":"<ul> <li>Tempo de Parada (\\(\\tau\\)): Vari\u00e1vel aleat\u00f3ria onde o evento \\(\\{\\tau = n\\} \\in A_n\\) (parar depende apenas do passado e presente).</li> <li>Teorema da Amostragem Opcional: Sob certas condi\u00e7\u00f5es, parar um martingale num tempo aleat\u00f3rio preserva a esperan\u00e7a: \\(E[M_{\\tau}] = E[M_0]\\).<ul> <li>Teorema de Doob: Se \\(\\tau\\) n\u00e3o for limitado, exige-se que o processo seja Uniformemente Integr\u00e1vel (U.I.).</li> </ul> </li> </ul>"},{"location":"capitulo5/teoria/#54","title":"4. Converg\u00eancia de Martingales","text":"<p>Um dos resultados centrais da teoria \u00e9 que martingales \"comportados\" estabilizam no longo prazo.</p> <ul> <li>Teorema da Converg\u00eancia: Se \\(\\sup_n E[|M_n|] &lt; \\infty\\), ent\u00e3o existe \\(M_{\\infty}\\) tal que \\(M_n \\to M_{\\infty}\\) quase certamente.</li> <li>Cadeias de Ramifica\u00e7\u00e3o: Se \\(\\eta\\) \u00e9 a m\u00e9dia de filhos, ent\u00e3o \\(W_n = \\frac{X_n}{\\eta^n}\\) \u00e9 um martingale que converge para \\(W\\).</li> </ul>"},{"location":"capitulo5/teoria/#55","title":"5. Desigualdades Maximais e Concentra\u00e7\u00e3o","text":"<p>Ferramentas para controlar o comportamento do m\u00e1ximo de um processo.</p> <ul> <li>Desigualdade Maximal de Doob: Para um submartingale n\u00e3o negativo:</li> </ul> <p>\\(P(\\max_{0 \\leq k \\leq n} M_k \\geq \\lambda) \\leq \\frac{E[M_n]}{\\lambda}\\)</p> <ul> <li>Desigualdade de Azuma-Hoeffding: Para martingales com incrementos limitados (\\(|M_n - M_{n-1}| \\leq c_n\\)):</li> </ul> <p>\\(P(M_n - M_0 \\geq \\lambda) \\leq \\exp\\left(-\\frac{\\lambda^2}{2 \\sum_{i=1}^{n} c_i^2}\\right)\\)</p> <ul> <li>Aplica\u00e7\u00e3o (\u00c1lbum de Figurinhas): A desigualdade de Azuma prova que o n\u00famero de pacotes necess\u00e1rios est\u00e1 altamente concentrado em torno da m\u00e9dia.</li> </ul>"},{"location":"capitulo6/exercicios/","title":"Exerc\u00edcios Resolvidos: Movimento Browniano","text":"<p>Esta p\u00e1gina cont\u00e9m resolu\u00e7\u00f5es detalhadas dos principais t\u00f3picos abordados no Cap\u00edtulo 6.</p>"},{"location":"capitulo6/exercicios/#ex61","title":"1. Propriedades de Escala e Vari\u00e2ncia","text":"<p>Enunciado: Seja \\((W_t)\\) um Movimento Browniano padr\u00e3o. Calcule a vari\u00e2ncia e a covari\u00e2ncia para os instantes \\(t=2\\) e \\(t=5\\).</p> <p>Resolu\u00e7\u00e3o: 1. Vari\u00e2ncia: Para o Movimento Browniano, \\(W_t \\sim N(0, t)\\).    * \\(Var(W_2) = 2\\)    * \\(Var(W_5) = 5\\) 2. Covari\u00e2ncia: A propriedade fundamental \u00e9 que \\(Cov(W_s, W_t) = \\min(s, t)\\).    * \\(Cov(W_2, W_5) = \\min(2, 5) = 2\\)</p>"},{"location":"capitulo6/exercicios/#ex62","title":"2. Princ\u00edpio da Reflex\u00e3o e M\u00e1ximo do Processo","text":"<p>Enunciado: Qual a probabilidade de um Movimento Browniano padr\u00e3o atingir o n\u00edvel \\(b=2\\) em algum momento antes do tempo \\(t=4\\)?</p> <p>Resolu\u00e7\u00e3o: 1. Seja \\(S_t = \\max_{0 \\leq s \\leq t} W_s\\). Queremos calcular \\(P(S_4 \\geq 2)\\). 2. Pelo Princ\u00edpio da Reflex\u00e3o: \\(P(S_t \\geq b) = 2P(W_t \\geq b)\\).    * \\(P(S_4 \\geq 2) = 2P(W_4 \\geq 2)\\) 3. Como \\(W_4 \\sim N(0, 4)\\), podemos normalizar para \\(Z \\sim N(0, 1)\\) usando \\(Z = W_4 / \\sqrt{4} = W_4 / 2\\):    * \\(2P(W_4 / 2 \\geq 2 / 2) = 2P(Z \\geq 1)\\) 4. Consultando a tabela da normal padr\u00e3o (\\(P(Z \\geq 1) \\approx 0.1587\\)):    * \\(P \\approx 2 \\cdot 0.1587 = 0.3174 \\text{ (ou 31,74%)}\\)</p>"},{"location":"capitulo6/exercicios/#ex63","title":"3. Movimento Browniano Geom\u00e9trico (MBG)","text":"<p>Enunciado: O pre\u00e7o de uma a\u00e7\u00e3o segue um MBG com \\(\\mu = 0.1\\) e \\(\\sigma = 0.2\\). Se o pre\u00e7o inicial \u00e9 \\(Y_0 = 100\\), qual o pre\u00e7o esperado ap\u00f3s 1 ano (\\(t=1\\))?</p> <p>Resolu\u00e7\u00e3o: 1. A f\u00f3rmula do pre\u00e7o esperado para o MBG \u00e9 \\(E[Y_t] = Y_0 e^{\\mu t}\\).    * \\(E[Y_1] = 100 \\cdot e^{0.1 \\cdot 1} = 100 \\cdot e^{0.1}\\) 2. Calculando o valor (\\(e^{0.1} \\approx 1.1052\\)):    * \\(E[Y_1] \\approx 100 \\cdot 1.1052 = 110,52\\)</p> <p>Nota: Observe que a tend\u00eancia do logaritmo (drift do \\(X_t\\)) \u00e9 \\(\\mu - \\sigma^2/2\\), mas a esperan\u00e7a do pre\u00e7o cresce puramente com \\(\\mu\\).</p>"},{"location":"capitulo6/exercicios/#ex64","title":"4. Varia\u00e7\u00e3o Quadr\u00e1tica e Regra de It\u00f4","text":"<p>Enunciado: Mostre que para um Movimento Browniano padr\u00e3o, a varia\u00e7\u00e3o quadr\u00e1tica esperada no intervalo \\([0, t]\\) \u00e9 igual a \\(t\\).</p> <p>Resolu\u00e7\u00e3o: 1. A varia\u00e7\u00e3o quadr\u00e1tica \u00e9 definida pelo limite da soma dos incrementos ao quadrado: \\(\\sum (W_{t_{i+1}} - W_{t_i})^2\\). 2. A esperan\u00e7a de cada incremento ao quadrado \u00e9 \\(E[(W_{t_{i+1}} - W_{t_i})^2] = Var(W_{t_{i+1}} - W_{t_i})\\). 3. Pela propriedade dos incrementos: \\(Var(W_{t_{i+1}} - W_{t_i}) = t_{i+1} - t_i\\). 4. Somando todos os intervalos da parti\u00e7\u00e3o:    \\(\\sum (t_{i+1} - t_i) = t\\)</p> <p>Conclus\u00e3o: No limite, a varia\u00e7\u00e3o quadr\u00e1tica converge para \\(t\\) quase certamente, o que justifica a regra \\((dW_t)^2 = dt\\) no C\u00e1lculo de It\u00f4.</p>"},{"location":"capitulo6/teoria/","title":"6. Movimento Browniano e Introdu\u00e7\u00e3o ao C\u00e1lculo Estoc\u00e1stico","text":"<p>Este cap\u00edtulo explora o Movimento Browniano, o processo estoc\u00e1stico fundamental para a modelagem de fen\u00f4menos cont\u00ednuos e a base do c\u00e1lculo de It\u00f4.</p>"},{"location":"capitulo6/teoria/#61","title":"1. Defini\u00e7\u00e3o e Caracteriza\u00e7\u00e3o","text":"<p>O Movimento Browniano \u00e9 apresentado como o limite cont\u00ednuo do Passeio Aleat\u00f3rio Simples.</p> <ul> <li> <p>Defini\u00e7\u00e3o Formal: Um processo \\((W_t : t \\geq 0)\\) \u00e9 um Movimento Browniano Padr\u00e3o se:</p> <ol> <li>In\u00edcio: \\(W_0 = 0\\).</li> <li>Incrementos Independentes e Gaussianos: Para quaisquer \\(0 = t_0 &lt; t_1 &lt; \\dots &lt; t_n\\), os incrementos \\(W_{t_{i+1}} - W_{t_i}\\) s\u00e3o independentes e \\(W_t - W_s \\sim N(0, t-s)\\).</li> <li>Trajet\u00f3rias Cont\u00ednuas: A fun\u00e7\u00e3o \\(t \\mapsto W_t(\\omega)\\) \u00e9 cont\u00ednua quase certamente.</li> </ol> </li> <li> <p>Movimento Browniano com Tend\u00eancia (Drift): Definido como \\(X_t = \\sigma W_t + \\mu t + x\\), onde \\(\\mu\\) \u00e9 a tend\u00eancia, \\(\\sigma^2\\) o coeficiente de difus\u00e3o e \\(x\\) a posi\u00e7\u00e3o inicial.</p> </li> <li>Teorema de Donsker: O movimento browniano pode ser visto como o limite de um passeio aleat\u00f3rio reescalado: \\(W_t^{(n)} \\approx S_{nt} / \\sqrt{n}\\).</li> </ul>"},{"location":"capitulo6/teoria/#62","title":"2. A Constru\u00e7\u00e3o de L\u00e9vy","text":"<p>Trata da exist\u00eancia matem\u00e1tica do processo atrav\u00e9s de interpola\u00e7\u00e3o em intervalos di\u00e1dicos.</p> <ul> <li>M\u00e9todo de Interpola\u00e7\u00e3o: Define-se \\(W\\) em \\(D_n = \\{k/2^n\\}\\). A distribui\u00e7\u00e3o de \\(W_t\\) dado \\(W_{t_1}\\) e \\(W_{t_2}\\) \u00e9 Gaussiana, permitindo a \"interpola\u00e7\u00e3o browniana\".</li> <li>Converg\u00eancia Uniforme: O Lema 6.2.2 garante que essas aproxima\u00e7\u00f5es convergem uniformemente, assegurando a continuidade das trajet\u00f3rias.</li> </ul>"},{"location":"capitulo6/teoria/#63","title":"3. Propriedades Fundamentais","text":"<ul> <li>Invari\u00e2ncia Escalar: Se \\(W_t\\) \u00e9 um movimento browniano, \\(c^{-1} W_{c^2 t}\\) tamb\u00e9m \u00e9 um movimento browniano padr\u00e3o para \\(c &gt; 0\\).</li> <li>Lei 0-1 de Blumenthal: Eventos que dependem apenas do comportamento infinitesimal perto de \\(t=0\\) t\u00eam probabilidade 0 ou 1.</li> <li>Comportamento no Infinito: Com probabilidade 1, \\(\\limsup_{t \\to \\infty} W_t = +\\infty\\) e \\(\\liminf_{t \\to \\infty} W_t = -\\infty\\).</li> </ul>"},{"location":"capitulo6/teoria/#64","title":"4. Propriedade de Markov e Reflex\u00e3o","text":"<ul> <li>Propriedade Forte de Markov: O rein\u00edcio probabil\u00edstico vale para Tempos de Parada \\((\\tau)\\) finitos.</li> <li>Princ\u00edpio da Reflex\u00e3o: Se o processo atinge um n\u00edvel \\(b\\), a trajet\u00f3ria futura pode ser refletida. Isso permite calcular a distribui\u00e7\u00e3o do m\u00e1ximo \\(S_t = \\sup_{s \\leq t} W_s\\):</li> </ul> <p>\\(P(S_t \\geq b) = P(|W_t| \\geq b) = 2P(W_t \\geq b)\\)</p>"},{"location":"capitulo6/teoria/#65","title":"5. Movimento Browniano Geom\u00e9trico e Finan\u00e7as","text":"<p>Base do modelo Black-Scholes.</p> <ul> <li>Defini\u00e7\u00e3o: \\(Y_t = Y_0 e^{(\\mu - \\sigma^2/2)t + \\sigma W_t}\\).</li> <li>Vantagens: Garante pre\u00e7os sempre positivos e modela retornos percentuais independentes.</li> <li>Salto-Difus\u00e3o de Merton: Adiciona um Processo de Poisson Composto para modelar choques bruscos.</li> </ul>"},{"location":"capitulo6/teoria/#66","title":"6. Propriedades das Trajet\u00f3rias (C\u00e1lculo)","text":"<ul> <li>N\u00e3o Diferenciabilidade: Com probabilidade 1, \\(W_t\\) n\u00e3o possui derivada em nenhum ponto.</li> <li>Varia\u00e7\u00e3o Quadr\u00e1tica: A soma dos quadrados dos incrementos converge para \\(t\\):</li> </ul> <p>\\(\\lim_{n \\to \\infty} \\sum (W_{t_{i+1}} - W_{t_i})^2 = t \\cdot \\sigma^2\\)</p> <p>Esta \u00e9 a base da regra de It\u00f4: \\((dW_t)^2 = dt\\).</p>"},{"location":"capitulo6/teoria/#67","title":"7. Introdu\u00e7\u00e3o \u00e0 Integral de It\u00f4","text":"<ul> <li>Motiva\u00e7\u00e3o: Dar sentido a Equa\u00e7\u00f5es Diferenciais Estoc\u00e1sticas (SDEs):</li> </ul> <p>\\(dX_t = \\mu(t, X_t) dt + \\sigma(t, X_t) dW_t\\)</p> <ul> <li>Forma Integral: \\(X_t = X_0 + \\int_0^t \\mu(s, X_s) ds + \\int_0^t \\sigma(s, X_s) dW_s\\). O segundo termo \u00e9 a Integral de It\u00f4, constru\u00edda como um limite de somas discretas adaptadas \u00e0 filtra\u00e7\u00e3o.</li> </ul>"}]}